{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3134515,"sourceType":"datasetVersion","datasetId":1909705}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/pythonimport numpy as np\nimport warnings  # Import the 'warnings' module for handling warnings\nwarnings.filterwarnings(\"ignore\") \n\nimport os\nfrom pathlib import Path\nimport numpy as np \nimport pandas as pd \nimport tensorflow as tf\n\n#additional (for visualization)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nfrom PIL import Image, ImageChops, ImageEnhance\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\nfrom tensorflow.keras import Input\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping,  LearningRateScheduler\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.regularizers import l1, l2\nfrom keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array, array_to_img","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_path = Path('/kaggle/input/deepfake-and-real-images/Dataset/Train/')\noutput_directory = '/kaggle/working/output'\nos.makedirs(output_directory, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:22:51.633128Z","iopub.execute_input":"2023-11-24T05:22:51.633871Z","iopub.status.idle":"2023-11-24T05:22:51.639358Z","shell.execute_reply.started":"2023-11-24T05:22:51.633831Z","shell.execute_reply":"2023-11-24T05:22:51.638238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_names = []\nlabels = []\n\n# Number of images to take from each folder\nnum_images_per_class = 5000\n\n# Iterate through both real and fake folders\nfor label in ['Real', 'Fake']:\n    label_path = dataset_path / label\n    for file in sorted(label_path.glob('*.*'))[:num_images_per_class]:\n        file_names.append(str(file))\n        labels.append(label)\n\n# Create a DataFrame\ndf = pd.DataFrame.from_dict({\"images\": file_names, \"labels\": labels})\nprint(df.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T02:33:11.154430Z","iopub.status.idle":"2023-11-24T02:33:11.154758Z","shell.execute_reply.started":"2023-11-24T02:33:11.154593Z","shell.execute_reply":"2023-11-24T02:33:11.154609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-23T18:28:33.012939Z","iopub.execute_input":"2023-11-23T18:28:33.013251Z","iopub.status.idle":"2023-11-23T18:28:33.030534Z","shell.execute_reply.started":"2023-11-23T18:28:33.013222Z","shell.execute_reply":"2023-11-23T18:28:33.029654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['labels'].unique()","metadata":{"execution":{"iopub.status.busy":"2023-11-23T18:28:33.031919Z","iopub.execute_input":"2023-11-23T18:28:33.032203Z","iopub.status.idle":"2023-11-23T18:28:33.043122Z","shell.execute_reply.started":"2023-11-23T18:28:33.032179Z","shell.execute_reply":"2023-11-23T18:28:33.042048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train, df_temp = train_test_split(df, test_size=0.2, random_state=42)\ndf_val, df_test= train_test_split(df_temp, test_size=0.5, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T18:28:33.044169Z","iopub.execute_input":"2023-11-23T18:28:33.044450Z","iopub.status.idle":"2023-11-23T18:28:33.057911Z","shell.execute_reply.started":"2023-11-23T18:28:33.044427Z","shell.execute_reply":"2023-11-23T18:28:33.056947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)\nval_datagen = ImageDataGenerator(rescale=1./255)\n\n# Create generators\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=df_train,\n    x_col='images',\n    y_col='labels',\n    class_mode='binary'\n)\n\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe=df_test,\n    x_col='images',\n    y_col='labels',\n    class_mode='binary'\n)\nvalidation_generator = val_datagen.flow_from_dataframe(\n    dataframe=df_val,\n    x_col='images',\n    y_col='labels',\n    class_mode='binary',\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T18:28:33.059043Z","iopub.execute_input":"2023-11-23T18:28:33.059359Z","iopub.status.idle":"2023-11-23T18:28:46.836710Z","shell.execute_reply.started":"2023-11-23T18:28:33.059334Z","shell.execute_reply":"2023-11-23T18:28:46.835782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unique_labels = df_train['labels'].unique()\n\nfor i, label in enumerate(unique_labels):\n    print(f\"Class {i}: Label {label}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-23T18:28:46.837947Z","iopub.execute_input":"2023-11-23T18:28:46.838225Z","iopub.status.idle":"2023-11-23T18:28:46.844279Z","shell.execute_reply.started":"2023-11-23T18:28:46.838200Z","shell.execute_reply":"2023-11-23T18:28:46.843321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_history(model_history):\n    fig,ax=plt.subplots(figsize=(15,5))\n    training_acc= [acc*100 for acc in model_history.history['accuracy']]\n    validation_acc = [acc*100 for acc in model_history.history['val_accuracy']]\n    ax.plot(training_acc, label='Training Accuracy')\n    ax.plot(validation_acc , label='Validation Accuracy')\n    ax.legend()\n    ax.grid(True)\n    ax.set_title('Model Accuracy')\n    ax.set_ylabel('Accuracy (%)')\n    ax.set_xlabel('Epochs')","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:22:51.640659Z","iopub.execute_input":"2023-11-24T05:22:51.641013Z","iopub.status.idle":"2023-11-24T05:22:51.672249Z","shell.execute_reply.started":"2023-11-24T05:22:51.640980Z","shell.execute_reply":"2023-11-24T05:22:51.671327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_images(generator, num_images, title):\n    plt.figure(figsize=(10, 5))\n    for i in range(num_images):\n        batch = next(generator)\n        image = batch[0][0]  # Extract the first image from the batch\n        label = batch[1][0]  # Extract the corresponding label\n        plt.subplot(2, 5, i + 1)\n        plt.imshow(image)\n        plt.title(f'{title} {i}, Label: {label}', pad=10)\n        plt.axis('off')\n    plt.subplots_adjust(hspace=0.8)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:22:51.674180Z","iopub.execute_input":"2023-11-24T05:22:51.674468Z","iopub.status.idle":"2023-11-24T05:22:51.683511Z","shell.execute_reply.started":"2023-11-24T05:22:51.674443Z","shell.execute_reply":"2023-11-24T05:22:51.682663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_eval(model,train_generator,test_generator):\n    train_evaluation = model.evaluate(train_generator)\n    test_evaluation = model.evaluate(test_generator)\n\n    print(\"Training Evaluation:\")\n    print(\"Loss:\", train_evaluation[0])\n    print(\"Accuracy:\", train_evaluation[1])\n\n    print(\"\\nTest Evaluation:\")\n    print(\"Loss:\", test_evaluation[0])\n    print(\"Accuracy:\", test_evaluation[1])","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:22:51.684539Z","iopub.execute_input":"2023-11-24T05:22:51.684833Z","iopub.status.idle":"2023-11-24T05:22:51.698196Z","shell.execute_reply.started":"2023-11-24T05:22:51.684797Z","shell.execute_reply":"2023-11-24T05:22:51.697134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def class_report_matrix(model,test_generator,class_names):\n    y_true = test_generator.classes\n    y_pred = model.predict(test_generator)\n    y_pred = np.where(y_pred > 0.48, 1, 0)\n    y_pred = np.squeeze(y_pred)\n    print(classification_report(y_true, y_pred))\n    conf_matrix = confusion_matrix(y_true, y_pred)\n    \n    plt.figure(figsize=(8, 8))\n    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:22:51.700256Z","iopub.execute_input":"2023-11-24T05:22:51.700558Z","iopub.status.idle":"2023-11-24T05:22:51.710323Z","shell.execute_reply.started":"2023-11-24T05:22:51.700520Z","shell.execute_reply":"2023-11-24T05:22:51.709016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot training images\nplot_images(train_generator, num_images=3, title='Train')\n\n# Plot test images\nplot_images(validation_generator, num_images=3, title='Test')\nunique_labels = df_train['labels'].unique()\n\n# 0= Fake\n# 1= Real","metadata":{"execution":{"iopub.status.busy":"2023-11-23T18:28:46.892180Z","iopub.execute_input":"2023-11-23T18:28:46.892462Z","iopub.status.idle":"2023-11-23T18:28:48.605879Z","shell.execute_reply.started":"2023-11-23T18:28:46.892433Z","shell.execute_reply":"2023-11-23T18:28:48.604896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_shape = 256","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:22:51.711490Z","iopub.execute_input":"2023-11-24T05:22:51.711850Z","iopub.status.idle":"2023-11-24T05:22:51.719431Z","shell.execute_reply.started":"2023-11-24T05:22:51.711817Z","shell.execute_reply":"2023-11-24T05:22:51.718557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# input_img = tf.keras.layers.Input(shape=(img_shape, img_shape, 3)) #(accepts only 256, 256, 3)\n\n# l1 = tf.keras.layers.Conv2D(32, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(input_img)\n# l2 = tf.keras.layers.MaxPool2D(padding='same')(l1)\n\n# l3 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(l2)\n# l4 = tf.keras.layers.MaxPool2D(padding='same')(l3)\n\n# l5 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_uniform', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(l4)\n# l6 = tf.keras.layers.MaxPool2D(padding='same')(l5)\n\n# l7= Flatten()(l6)\n# l7 = Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(l7)\n# l7 = Dropout(0.5)(l7)\n# output_img = Dense(1, activation='sigmoid')(l7)\n\ndetector1 =models.Sequential([\n    layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu',kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001), input_shape=(img_shape, img_shape, 3)),\n    layers.BatchNormalization(),\n    layers.MaxPool2D(pool_size=(2,2)),\n    layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding=\"same\",kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n    layers.BatchNormalization(),\n    layers.MaxPool2D(pool_size=(3,3)),\n    layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding=\"same\",kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n    layers.BatchNormalization(),\n#     layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding=\"same\",kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n#     layers.BatchNormalization(),\n#     layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding=\"same\",kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n#     layers.BatchNormalization(),\n    layers.MaxPool2D(pool_size=(2,2)),\n    layers.Flatten(),\n    layers.Dense(256,activation='relu'),\n    layers.Dropout(0.3),\n    layers.Dense(1,activation='sigmoid')  \n])","metadata":{"execution":{"iopub.status.busy":"2023-11-23T18:28:48.613376Z","iopub.execute_input":"2023-11-23T18:28:48.613636Z","iopub.status.idle":"2023-11-23T18:28:52.811315Z","shell.execute_reply.started":"2023-11-23T18:28:48.613613Z","shell.execute_reply":"2023-11-23T18:28:52.810481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# detector1 = tf.keras.models.Model(inputs=(input_img), outputs=output_img)\ndetector1.compile(optimizer=Adam(learning_rate=0.00005), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2023-11-23T18:28:52.812502Z","iopub.execute_input":"2023-11-23T18:28:52.812858Z","iopub.status.idle":"2023-11-23T18:28:52.830529Z","shell.execute_reply.started":"2023-11-23T18:28:52.812820Z","shell.execute_reply":"2023-11-23T18:28:52.829804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"detector1.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-23T18:28:52.831832Z","iopub.execute_input":"2023-11-23T18:28:52.832509Z","iopub.status.idle":"2023-11-23T18:28:52.875278Z","shell.execute_reply.started":"2023-11-23T18:28:52.832465Z","shell.execute_reply":"2023-11-23T18:28:52.874345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint1 = ModelCheckpoint(os.path.join(output_directory, \"cnn_model_weights.h5\"), \n                              save_best_only=True, \n                              monitor=\"val_loss\", \n                              mode=\"min\")","metadata":{"execution":{"iopub.status.busy":"2023-11-23T18:28:52.876840Z","iopub.execute_input":"2023-11-23T18:28:52.877099Z","iopub.status.idle":"2023-11-23T18:28:52.881922Z","shell.execute_reply.started":"2023-11-23T18:28:52.877077Z","shell.execute_reply":"2023-11-23T18:28:52.880966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', \n                               patience=5,\n                               mode='min',\n                               restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:22:55.333863Z","iopub.execute_input":"2023-11-24T05:22:55.334241Z","iopub.status.idle":"2023-11-24T05:22:55.338830Z","shell.execute_reply.started":"2023-11-24T05:22:55.334210Z","shell.execute_reply":"2023-11-24T05:22:55.337892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history1 =detector1.fit(\n    train_generator,\n    epochs=100,\n    validation_data=validation_generator,\n    callbacks=[checkpoint1, early_stopping]\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:12:36.157783Z","iopub.execute_input":"2023-11-23T00:12:36.158472Z","iopub.status.idle":"2023-11-23T00:15:52.125916Z","shell.execute_reply.started":"2023-11-23T00:12:36.158440Z","shell.execute_reply":"2023-11-23T00:15:52.124941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(history1)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:15:52.127919Z","iopub.execute_input":"2023-11-23T00:15:52.128598Z","iopub.status.idle":"2023-11-23T00:15:52.492548Z","shell.execute_reply.started":"2023-11-23T00:15:52.128560Z","shell.execute_reply":"2023-11-23T00:15:52.491455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"detector1.load_weights(os.path.join(output_directory, \"cnn_model_weights.h5\"))","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:15:52.493675Z","iopub.execute_input":"2023-11-23T00:15:52.493937Z","iopub.status.idle":"2023-11-23T00:15:52.581613Z","shell.execute_reply.started":"2023-11-23T00:15:52.493914Z","shell.execute_reply":"2023-11-23T00:15:52.580805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_eval(detector1,train_generator,test_generator)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:15:52.583338Z","iopub.execute_input":"2023-11-23T00:15:52.583644Z","iopub.status.idle":"2023-11-23T00:16:12.719911Z","shell.execute_reply.started":"2023-11-23T00:15:52.583618Z","shell.execute_reply":"2023-11-23T00:16:12.718941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = [\"Real\", \"Fake\"]\nclass_report_matrix(detector1,test_generator,class_names)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T00:16:12.721267Z","iopub.execute_input":"2023-11-23T00:16:12.721618Z","iopub.status.idle":"2023-11-23T00:16:15.718936Z","shell.execute_reply.started":"2023-11-23T00:16:12.721589Z","shell.execute_reply":"2023-11-23T00:16:15.717959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model with error-level analysis","metadata":{}},{"cell_type":"code","source":"def error_level_analysis(img_path):\n    \n    og_img = Image.open(img_path).convert('RGB')\n    act_img = og_img\n    temp_img_path = \"temp.jpg\"\n    og_img.save(temp_img_path, quality=90)\n\n    temp_img = Image.open(temp_img_path)\n    ela_img = ImageChops.difference(og_img, temp_img)\n\n    extrema = ela_img.getextrema()\n    max_diff = max([ex[1] for ex in extrema])\n    if max_diff == 0:\n        max_diff = 1\n    scale = 255.0 / max_diff\n\n    ela_img = ImageEnhance.Brightness(ela_img).enhance(scale)\n\n    return act_img, ela_img","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:22:59.162765Z","iopub.execute_input":"2023-11-24T05:22:59.163580Z","iopub.status.idle":"2023-11-24T05:22:59.169680Z","shell.execute_reply.started":"2023-11-24T05:22:59.163545Z","shell.execute_reply":"2023-11-24T05:22:59.168736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_images(data_path, label, num_images=5000):\n    act_images=[]\n    images = []\n    labels = []\n\n    for filename in os.listdir(data_path)[:num_images]:\n        if filename.endswith('.jpg'):\n            img_path = os.path.join(data_path, filename)\n            act_img, ela_img = error_level_analysis(img_path)\n            act_images.append(act_img)\n            images.append(ela_img)\n            labels.append(label)\n\n    return act_images, images, labels\n\nact_real_images, real_images, real_labels = process_images('/kaggle/input/deepfake-and-real-images/Dataset/Train/Real', label=1)\nact_fake_images, fake_images, fake_labels = process_images('/kaggle/input/deepfake-and-real-images/Dataset/Train/Fake', label=0)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:22:59.440486Z","iopub.execute_input":"2023-11-24T05:22:59.441378Z","iopub.status.idle":"2023-11-24T05:24:40.557801Z","shell.execute_reply.started":"2023-11-24T05:22:59.441345Z","shell.execute_reply":"2023-11-24T05:24:40.556870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"real_df = pd.DataFrame({'images': real_images, 'labels': real_labels})\nfake_df = pd.DataFrame({'images': fake_images, 'labels': fake_labels})\nogreal_df = pd.DataFrame({'ogimages': act_real_images})\nogfake_df = pd.DataFrame({'ogimages': act_fake_images})\ndf_ela = pd.concat([real_df, fake_df], ignore_index=True)\ndf_og = pd.concat([ogreal_df, ogfake_df], ignore_index=True)\n\ndf= pd.concat([df_og, df_ela], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:24:40.559740Z","iopub.execute_input":"2023-11-24T05:24:40.560048Z","iopub.status.idle":"2023-11-24T05:24:45.011967Z","shell.execute_reply.started":"2023-11-24T05:24:40.560020Z","shell.execute_reply":"2023-11-24T05:24:45.011054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_ela.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:24:45.013414Z","iopub.execute_input":"2023-11-24T05:24:45.013763Z","iopub.status.idle":"2023-11-24T05:24:45.017946Z","shell.execute_reply.started":"2023-11-24T05:24:45.013734Z","shell.execute_reply":"2023-11-24T05:24:45.016874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:24:45.020396Z","iopub.execute_input":"2023-11-24T05:24:45.020707Z","iopub.status.idle":"2023-11-24T05:24:45.028604Z","shell.execute_reply.started":"2023-11-24T05:24:45.020681Z","shell.execute_reply":"2023-11-24T05:24:45.027673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df, test_val_df = train_test_split(df_ela, test_size=0.2, random_state=42)\ntest_df, val_df = train_test_split(test_val_df, test_size=0.5, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T05:24:45.029771Z","iopub.execute_input":"2023-11-24T05:24:45.030088Z","iopub.status.idle":"2023-11-24T05:24:45.046058Z","shell.execute_reply.started":"2023-11-24T05:24:45.030062Z","shell.execute_reply":"2023-11-24T05:24:45.044934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images = [np.array(img) for img in train_df['images']]\ntest_images = [np.array(img) for img in test_df['images']]\nval_images = [np.array(img) for img in val_df['images']]\n\nX_train = np.array(train_images)/ 255.0\nX_test = np.array(test_images)/ 255.0\nX_val = np.array(val_images) / 255.0\n\ny_train = train_df['labels'].values\ny_test = test_df['labels'].values\ny_val = val_df['labels'].values","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:47:49.635565Z","iopub.execute_input":"2023-11-24T07:47:49.636259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_images(X,y, num_images=3):\n    plt.figure(figsize=(10, 5))\n    for i in range(num_images):\n        plt.subplot(1, num_images, i + 1)\n        plt.imshow(X[i])\n        plt.title(f'Label: {y[i]}')\n        plt.axis('off')\n\n    plt.tight_layout()\n    plt.show()\n\n# Show images in the training set\nshow_images(X_train, y_train)\n\n# Show images in the testing set\nshow_images(X_test, y_test)\n\n# Show images in the validation set\nshow_images(X_val, y_val)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# detector2 =models.Sequential([\n#     layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu',kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001), input_shape=(img_shape, img_shape, 3)),\n#     layers.BatchNormalization(),\n#     layers.MaxPool2D(pool_size=(2,2)),\n#     layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding=\"same\",kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n#     layers.BatchNormalization(),\n#     layers.MaxPool2D(pool_size=(3,3)),\n#     layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding=\"same\",kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n#     layers.BatchNormalization(),\n# #     layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding=\"same\",kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n# #     layers.BatchNormalization(),\n# #     layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding=\"same\",kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n# #     layers.BatchNormalization(),\n#     layers.MaxPool2D(pool_size=(2,2)),\n#     layers.Flatten(),\n#     layers.Dense(256,activation='relu'),\n#     layers.Dropout(0.3),\n#     layers.Dense(1,activation='sigmoid')  \n# ])\n\ndetector2 =models.Sequential([\n#     layers.Conv2D(filters=4, kernel_size = (6,6), activation='relu',kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001), input_shape=(img_shape, img_shape, 3)),\n#     layers.MaxPool2D(),\n#     layers.BatchNormalization(),\n#     layers.Conv2D(filters=8, kernel_size = (5,5), activation='relu',kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n#     layers.MaxPool2D(),\n#     layers.BatchNormalization(),\n#     layers.Conv2D(filters=16, kernel_size=(4,4), activation='relu', padding=\"same\",kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n#     layers.MaxPool2D(),\n#     layers.BatchNormalization(),\n#     layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding=\"same\",kernel_initializer='he_uniform', kernel_regularizer=l2(0.0001)),\n    layers.Conv2D(filters=32, kernel_size = (3,3), activation='relu',kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001), input_shape=(img_shape, img_shape, 3)),\n    layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding=\"same\",kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n    layers.MaxPool2D(),\n    layers.BatchNormalization(),\n    layers.Conv2D(filters=64, kernel_size=(2,2), activation='relu', padding=\"same\",kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n    layers.Conv2D(filters=64, kernel_size=(2,2), activation='relu', padding=\"same\",kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n    layers.MaxPool2D(),\n    layers.BatchNormalization(),\n    layers.Conv2D(filters=128, kernel_size=(1,1), activation='relu', padding=\"same\",kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n    layers.Conv2D(filters=128, kernel_size=(1,1), activation='relu', padding=\"same\",kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001)),\n    layers.MaxPool2D(),\n    layers.BatchNormalization(),\n    layers.Flatten(),\n    layers.Dense(256,activation='relu'),\n    layers.Dropout(0.5),\n    layers.Dense(1,activation='sigmoid')  \n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"initial_learning_rate = 0.001\nlr_schedule = ExponentialDecay(\n    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n)\n\nrms_opt = RMSprop(learning_rate=lr_schedule, rho=0.9, epsilon=1e-08)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"detector2.compile(optimizer=Adam(learning_rate=0.000001), loss='binary_crossentropy', metrics=['accuracy'])\n# detector2.compile(optimizer=rms_opt, loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"detector2.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint2 = ModelCheckpoint(os.path.join(output_directory, \"cnn_ela_model_weights.h5\"), \n                              save_best_only=True, \n                              monitor=\"val_accuracy\", \n                              mode=\"min\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lr_schedule(epoch):\n    initial_lr = 0.001\n    if epoch < 50:\n        return initial_lr\n    elif epoch < 75:\n        return initial_lr * 0.1\n    else:\n        return initial_lr * 0.01\n\nlr_scheduler = LearningRateScheduler(lr_schedule)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history2 = detector2.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), callbacks=[checkpoint2, early_stopping])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(history2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"detector2.load_weights(os.path.join(output_directory, \"cnn_ela_model_weights.h5\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_evaluation = detector2.evaluate(X_train, y_train)\ntest_evaluation = detector2.evaluate(X_test, y_test)\n\nprint(\"Training Evaluation:\")\nprint(\"Loss:\", train_evaluation[0])\nprint(\"Accuracy:\", train_evaluation[1])\n\nprint(\"\\nTest Evaluation:\")\nprint(\"Loss:\", test_evaluation[0])\nprint(\"Accuracy:\", test_evaluation[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names = ['Fake','Real']\ny_true = y_test\ny_pred = detector2.predict(X_test)\ny_pred = np.where(y_pred > 0.5, 1, 0)\ny_pred = np.squeeze(y_pred)\nprint(classification_report(y_true, y_pred))\nconf_matrix = confusion_matrix(y_true, y_pred)\n\nplt.figure(figsize=(8, 8))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir = '/kaggle/input/deepfake-and-real-images/Dataset/Train'\ntest_dir = '/kaggle/input/deepfake-and-real-images/Dataset/Test'\nvalidation_dir = '/kaggle/input/deepfake-and-real-images/Dataset/Validation'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ensemble Learning Model with ELA images","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transfer Learning model with VGG19 using ELA images","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}